# -*- coding: utf-8 -*-
"""dl_project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-28zgvoKVU4z9NJBsh4-udbvs2Xfz5lN
"""

import numpy as np
import cv2
import mrcnn.config
import mrcnn.utils
from mrcnn import visualize
from mrcnn.model import MaskRCNN
from pathlib import Path
from twilio.rest import Client
from google.colab.patches import cv2_imshow
from qiniu import Auth, put_file, etag
import qiniu.config
import time

class MaskRCNNConfig(mrcnn.config.Config):
    NAME = "coco_pretrained_model_config"
    IMAGES_PER_GPU = 1
    GPU_COUNT = 1
    NUM_CLASSES = 1 + 80 
    DETECTION_MIN_CONFIDENCE = 0.6


def get_car_boxes(boxes, class_ids):
    car_boxes = []
    for i, box in enumerate(boxes):
        # If the detected object isn't a car / truck, skip it
        if class_ids[i] in [3, 8, 6]:
            car_boxes.append(box)
    return np.array(car_boxes)

# Twilio config
twilio_account_sid = ''
twilio_auth_token = ''
twilio_phone_number = 'your twilio number'
destination_phone_number = 'the number you want to receive the message'
client = Client(twilio_account_sid, twilio_auth_token)

ROOT_DIR = Path("./")

MODEL_DIR = os.path.join(ROOT_DIR, "logs")

COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco.h5")

# Download COCO pre-trained weights 
if not os.path.exists(COCO_MODEL_PATH):
    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)

IMAGE_DIR = os.path.join(ROOT_DIR, "images")

#VIDEO_SOURCE = "/content/drive/My Drive/Study @ Fordham/Deep Learning - Parking Spots Hunter/test_images/parking.mp4.mp4"
VIDEO_SOURCE = "/test_video/Clip (October 22 2019 at 305 PM).mp4"
#VIDEO_SOURCE = "/content/drive/My Drive/Study @ Fordham/Deep Learning - Parking Spots Hunter/test3.mp4"


model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig())
# Load pre-trained model
model.load_weights(COCO_MODEL_PATH, by_name=True)

# Location of parking spaces
parked_car_boxes = None


video_capture = cv2.VideoCapture(VIDEO_SOURCE)

free_space_frames = 0

sms_sent = False

total_space=5

# How many frames we skip by one catching?
INTERVAL = 100 
i = 0  # Initialize the frame counter

if video_capture.isOpened(): 
  rval, frame = video_capture.read()
else:
  rval = False
# Loop over each frame of video
while rval:
    rval, frame = video_capture.read()
    # catch the picture per interval frames
    if ( i % INTERVAL ) == 0:

        # Convert the image from BGR color (which OpenCV uses) to RGB color
        rgb_image = frame[:, :, ::-1]

        # Run the image through the Mask R-CNN model to get results.
        results = model.detect([rgb_image], verbose=0)

        # Mask R-CNN assumes we are running detection on multiple images.
        # We only passed in one image to detect, so only grab the first result.
        r = results[0]

        # The r variable will now have the results of detection:
        # - r['rois'] are the bounding box of each detected object
        # - r['class_ids'] are the class id (type) of each detected object
        # - r['scores'] are the confidence scores for each detection
        # - r['masks'] are the object masks for each detected object (which gives you the object outline)

        if parked_car_boxes is None:
            # This is the first frame of video - assume all the cars detected are in parking spaces.
            # Save the location of each car as a parking space box and go to the next frame of video.
            parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])
        else:
            # We already know where the parking spaces are. Check if any are currently unoccupied.

            # Get where cars are currently located in the frame
            car_boxes = get_car_boxes(r['rois'], r['class_ids'])

            # See how much those cars overlap with the known parking spaces
            overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes)

            # Assume no spaces are free until we find one that is free
            free_space = False

            # Loop through each known parking space box
            for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):

                # For this parking space, find the max amount it was covered by any
                # car that was detected in our image (doesn't really matter which car)
                max_IoU_overlap = np.max(overlap_areas)

                # Get the top-left and bottom-right coordinates of the parking area
                y1, x1, y2, x2 = parking_area

                # Check if the parking space is occupied by seeing if any car overlaps
                # it by more than 0.3 using IoU
                if max_IoU_overlap < 0.3:
                    # Parking space not occupied! Draw a green box around it
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4)
                    # Flag that we have seen at least one open space
                    free_space = True
                else:
                    # Parking space is still occupied - draw a yellow box around it
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)

                # Write the IoU measurement inside the box
                font = cv2.FONT_HERSHEY_DUPLEX
                cv2.putText(frame, f"{max_IoU_overlap:0.3}", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))

            # If at least one space was free, start counting frames
            # This is so we don't alert based on one frame of a spot being open.
            # This helps prevent the script triggered on one bad detection.
            if free_space:
                free_space_frames += 1
            else:
                # If no spots are free, reset the count
                free_space_frames = 0

            # If a space has been free for several frames, we are pretty sure it is really free!
            if free_space_frames > 5:
                # Write texts at the top of the screen
                font = cv2.FONT_HERSHEY_DUPLEX
                s="Parking Space Available: {n} Remaining"
                p="Parking Space Available: {n} Remaining"
                cv2.putText(frame, p.format(n=total_space-len(parked_car_boxes)+1), (20, 1020), font, 2.5, (255, 255, 255), 2, cv2.FILLED)
                os.chdir(r'/content/drive/My Drive') 
                files=int(time.time())
                filename='{files}.jpg'
                cv2.imwrite(filename.format(files=files), frame)
                access_key = '6DNRIFZ-yjWcn3HFsH_tGmn_IZ_3964cQb_YDqHi'
                secret_key = 'qiOoHluZ9IoNA1wMLKKSxwHdP9rPGYEp3e8xT5A2'
                bucket_name = 'cisc6000'
                key = filename.format(files=files)
                q = Auth(access_key, secret_key)
                token = q.upload_token(bucket_name, key, 3600)
                localfile = '/content/drive/My Drive/'+filename.format(files=files)
                ret, info = put_file(token, key, localfile)
                assert ret['key'] == key
                assert ret['hash'] == etag(localfile)
                # If we haven't sent an SMS yet, sent it!
                if not sms_sent:
                    print("Sending...")
                    s="Parking Space Available: {n} Remaining"
                    message = client.messages.create(
                        body=s.format(n=total_space-len(parked_car_boxes)+1),
                        from_=twilio_phone_number,
                        media_url=['http://q2989xg5x.bkt.gdipper.com/'+filename.format(files=files)],
                        to=destination_phone_number
                    )
                    sms_sent = True

            # Show the frame of video on the screen
            cv2_imshow(frame)

    i += 1 # add up the frame counter

    # Hit 'q' to quit
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Clean up everything when finished
video_capture.release()
cv2.destroyAllWindows()
